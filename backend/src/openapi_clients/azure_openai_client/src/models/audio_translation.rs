/*
 * Azure OpenAI API
 *
 * Azure OpenAI APIs for completions and search
 *
 * The version of the OpenAPI document: 2024-05-01-preview
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// AudioTranslation : Result information for an operation that translated spoken audio into written text.
#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct AudioTranslation {
    /// The translated text for the provided audio data.
    #[serde(rename = "text")]
    pub text: String,
    #[serde(rename = "task", skip_serializing_if = "Option::is_none")]
    pub task: Option<models::AudioTaskLabel>,
    /// The spoken language that was detected in the translated audio data. This is expressed as a two-letter ISO-639-1 language code like 'en' or 'fr'.
    #[serde(rename = "language", skip_serializing_if = "Option::is_none")]
    pub language: Option<String>,
    /// The total duration of the audio processed to produce accompanying translation information.
    #[serde(rename = "duration", skip_serializing_if = "Option::is_none")]
    pub duration: Option<f32>,
    /// A collection of information about the timing, probabilities, and other detail of each processed audio segment.
    #[serde(rename = "segments", skip_serializing_if = "Option::is_none")]
    pub segments: Option<Vec<models::AudioTranslationSegment>>,
}

impl AudioTranslation {
    /// Result information for an operation that translated spoken audio into written text.
    pub fn new(text: String) -> AudioTranslation {
        AudioTranslation {
            text,
            task: None,
            language: None,
            duration: None,
            segments: None,
        }
    }
}


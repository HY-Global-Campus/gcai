/*
 * Azure OpenAI API
 *
 * Azure OpenAI APIs for completions and search
 *
 * The version of the OpenAPI document: 2024-05-01-preview
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// ChatCompletions : Representation of the response data from a chat completions request. Completions support a wide variety of tasks and generate text that continues from or \"completes\" provided prompt data.
#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct ChatCompletions {
    /// A unique identifier associated with this chat completions response.
    #[serde(rename = "id")]
    pub id: String,
    /// The first timestamp associated with generation activity for this completions response, represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan 1970.
    #[serde(rename = "created")]
    pub created: i32,
    /// The collection of completions choices associated with this completions response. Generally, `n` choices are generated per provided prompt with a default value of 1. Token limits and other settings may limit the number of choices generated.
    #[serde(rename = "choices")]
    pub choices: Vec<models::ChatChoice>,
    /// The model name used for this completions request.
    #[serde(rename = "model", skip_serializing_if = "Option::is_none")]
    pub model: Option<String>,
    /// Content filtering results for zero or more prompts in the request. In a streaming request, results for different prompts may arrive at different times or in different orders.
    #[serde(rename = "prompt_filter_results", skip_serializing_if = "Option::is_none")]
    pub prompt_filter_results: Option<Vec<models::ContentFilterResultsForPrompt>>,
    /// Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
    #[serde(rename = "system_fingerprint", skip_serializing_if = "Option::is_none")]
    pub system_fingerprint: Option<String>,
    #[serde(rename = "usage")]
    pub usage: Box<models::CompletionsUsage>,
}

impl ChatCompletions {
    /// Representation of the response data from a chat completions request. Completions support a wide variety of tasks and generate text that continues from or \"completes\" provided prompt data.
    pub fn new(id: String, created: i32, choices: Vec<models::ChatChoice>, usage: models::CompletionsUsage) -> ChatCompletions {
        ChatCompletions {
            id,
            created,
            choices,
            model: None,
            prompt_filter_results: None,
            system_fingerprint: None,
            usage: Box::new(usage),
        }
    }
}


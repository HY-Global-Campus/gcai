/*
 * Azure OpenAI API
 *
 * Azure OpenAI APIs for completions and search
 *
 * The version of the OpenAPI document: 2024-10-01-preview
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// AudioTranscription : Result information for an operation that transcribed spoken audio into written text.
#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct AudioTranscription {
    /// The transcribed text for the provided audio data.
    #[serde(rename = "text")]
    pub text: String,
    #[serde(rename = "task", skip_serializing_if = "Option::is_none")]
    pub task: Option<models::AudioTaskLabel>,
    /// The spoken language that was detected in the transcribed audio data. This is expressed as a two-letter ISO-639-1 language code like 'en' or 'fr'.
    #[serde(rename = "language", skip_serializing_if = "Option::is_none")]
    pub language: Option<String>,
    /// The total duration of the audio processed to produce accompanying transcription information.
    #[serde(rename = "duration", skip_serializing_if = "Option::is_none")]
    pub duration: Option<f32>,
    /// A collection of information about the timing, probabilities, and other detail of each processed audio segment.
    #[serde(rename = "segments", skip_serializing_if = "Option::is_none")]
    pub segments: Option<Vec<models::AudioTranscriptionSegment>>,
    /// A collection of information about the timing of each processed word.
    #[serde(rename = "words", skip_serializing_if = "Option::is_none")]
    pub words: Option<Vec<models::AudioTranscriptionWord>>,
}

impl AudioTranscription {
    /// Result information for an operation that transcribed spoken audio into written text.
    pub fn new(text: String) -> AudioTranscription {
        AudioTranscription {
            text,
            task: None,
            language: None,
            duration: None,
            segments: None,
            words: None,
        }
    }
}


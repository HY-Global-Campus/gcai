/*
 * Azure OpenAI API
 *
 * Azure OpenAI APIs for completions and search
 *
 * The version of the OpenAPI document: 2024-05-01-preview
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// ChatRequestAssistantMessage : A request chat message representing response or action from the assistant.
#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct ChatRequestAssistantMessage {
    /// The content of the message.
    #[serde(rename = "content", deserialize_with = "Option::deserialize")]
    pub content: Option<String>,
    /// An optional name for the participant.
    #[serde(rename = "name", skip_serializing_if = "Option::is_none")]
    pub name: Option<String>,
    /// The tool calls that must be resolved and have their outputs appended to subsequent input messages for the chat completions request to resolve as configured.
    #[serde(rename = "tool_calls", skip_serializing_if = "Option::is_none")]
    pub tool_calls: Option<Vec<models::ChatCompletionsToolCall>>,
    #[serde(rename = "function_call", skip_serializing_if = "Option::is_none")]
    pub function_call: Option<Box<models::FunctionCall>>,
    #[serde(rename = "role")]
    pub role: models::ChatRole,
}

impl ChatRequestAssistantMessage {
    /// A request chat message representing response or action from the assistant.
    pub fn new(content: Option<String>, role: models::ChatRole) -> ChatRequestAssistantMessage {
        ChatRequestAssistantMessage {
            content,
            name: None,
            tool_calls: None,
            function_call: None,
            role,
        }
    }
}


/*
 * Azure OpenAI API
 *
 * Azure OpenAI APIs for completions and search
 *
 * The version of the OpenAPI document: 2024-10-01-preview
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// Choice : The representation of a single prompt completion as part of an overall completions request. Generally, `n` choices are generated per provided prompt with a default value of 1. Token limits and other settings may limit the number of choices generated.
#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct Choice {
    /// The generated text for a given completions prompt.
    #[serde(rename = "text")]
    pub text: String,
    /// The ordered index associated with this completions choice.
    #[serde(rename = "index")]
    pub index: i32,
    #[serde(rename = "content_filter_results", skip_serializing_if = "Option::is_none")]
    pub content_filter_results: Option<Box<models::ContentFilterResultsForChoice>>,
    /// The log probabilities model for tokens associated with this completions choice.
    #[serde(rename = "logprobs", deserialize_with = "Option::deserialize")]
    pub logprobs: Option<Box<models::CompletionsLogProbabilityModel>>,
    #[serde(rename = "finish_reason")]
    pub finish_reason: models::CompletionsFinishReason,
}

impl Choice {
    /// The representation of a single prompt completion as part of an overall completions request. Generally, `n` choices are generated per provided prompt with a default value of 1. Token limits and other settings may limit the number of choices generated.
    pub fn new(text: String, index: i32, logprobs: Option<models::CompletionsLogProbabilityModel>, finish_reason: models::CompletionsFinishReason) -> Choice {
        Choice {
            text,
            index,
            content_filter_results: None,
            logprobs: if let Some(x) = logprobs {Some(Box::new(x))} else {None},
            finish_reason,
        }
    }
}


/*
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * 
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// RealtimeSession : Realtime session object configuration.
#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct RealtimeSession {
    /// The set of modalities the model can respond with. To disable audio, set this to [\"text\"]. 
    #[serde(rename = "modalities", skip_serializing_if = "Option::is_none")]
    pub modalities: Option<Vec<Modalities>>,
    /// The default system instructions (i.e. system message) prepended to model  calls. This field allows the client to guide the model on desired  responses. The model can be instructed on response content and format,  (e.g. \"be extremely succinct\", \"act friendly\", \"here are examples of good  responses\") and on audio behavior (e.g. \"talk quickly\", \"inject emotion  into your voice\", \"laugh frequently\"). The instructions are not guaranteed  to be followed by the model, but they provide guidance to the model on the  desired behavior.  Note that the server sets default instructions which will be used if this  field is not set and are visible in the `session.created` event at the  start of the session. 
    #[serde(rename = "instructions", skip_serializing_if = "Option::is_none")]
    pub instructions: Option<String>,
    /// The voice the model uses to respond. Current voice options are `ash`,  `ballad`, `coral`, `sage`, and `verse`.   Also supported but not recommended are `alloy`, `echo`, and `shimmer`.  These older voices are less expressive.   Voice cannot be changed during the session once the model has  responded with audio at least once. 
    #[serde(rename = "voice", skip_serializing_if = "Option::is_none")]
    pub voice: Option<Voice>,
    /// The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. 
    #[serde(rename = "input_audio_format", skip_serializing_if = "Option::is_none")]
    pub input_audio_format: Option<String>,
    /// The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. 
    #[serde(rename = "output_audio_format", skip_serializing_if = "Option::is_none")]
    pub output_audio_format: Option<String>,
    #[serde(rename = "input_audio_transcription", skip_serializing_if = "Option::is_none")]
    pub input_audio_transcription: Option<Box<models::RealtimeSessionInputAudioTranscription>>,
    #[serde(rename = "turn_detection", skip_serializing_if = "Option::is_none")]
    pub turn_detection: Option<Box<models::RealtimeSessionTurnDetection>>,
    /// Tools (functions) available to the model.
    #[serde(rename = "tools", skip_serializing_if = "Option::is_none")]
    pub tools: Option<Vec<models::RealtimeSessionToolsInner>>,
    /// How the model chooses tools. Options are `auto`, `none`, `required`, or  specify a function. 
    #[serde(rename = "tool_choice", skip_serializing_if = "Option::is_none")]
    pub tool_choice: Option<String>,
    /// Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8. 
    #[serde(rename = "temperature", skip_serializing_if = "Option::is_none")]
    pub temperature: Option<f64>,
    #[serde(rename = "max_response_output_tokens", skip_serializing_if = "Option::is_none")]
    pub max_response_output_tokens: Option<Box<models::RealtimeSessionMaxResponseOutputTokens>>,
}

impl RealtimeSession {
    /// Realtime session object configuration.
    pub fn new() -> RealtimeSession {
        RealtimeSession {
            modalities: None,
            instructions: None,
            voice: None,
            input_audio_format: None,
            output_audio_format: None,
            input_audio_transcription: None,
            turn_detection: None,
            tools: None,
            tool_choice: None,
            temperature: None,
            max_response_output_tokens: None,
        }
    }
}
/// The set of modalities the model can respond with. To disable audio, set this to [\"text\"]. 
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum Modalities {
    #[serde(rename = "text")]
    Text,
    #[serde(rename = "audio")]
    Audio,
}

impl Default for Modalities {
    fn default() -> Modalities {
        Self::Text
    }
}
/// The voice the model uses to respond. Current voice options are `ash`,  `ballad`, `coral`, `sage`, and `verse`.   Also supported but not recommended are `alloy`, `echo`, and `shimmer`.  These older voices are less expressive.   Voice cannot be changed during the session once the model has  responded with audio at least once. 
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum Voice {
    #[serde(rename = "alloy")]
    Alloy,
    #[serde(rename = "ash")]
    Ash,
    #[serde(rename = "ballad")]
    Ballad,
    #[serde(rename = "coral")]
    Coral,
    #[serde(rename = "echo")]
    Echo,
    #[serde(rename = "sage")]
    Sage,
    #[serde(rename = "shimmer")]
    Shimmer,
    #[serde(rename = "verse")]
    Verse,
}

impl Default for Voice {
    fn default() -> Voice {
        Self::Alloy
    }
}

